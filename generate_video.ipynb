{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:24:56.875405861Z",
     "start_time": "2024-01-26T07:24:51.120812144Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from shutil import copy\n",
    "\n",
    "from src.gradio_demo import SadTalker\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from elevenlabs import generate, save, set_api_key\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "\n",
    "set_api_key('28df0b632b692bda62e579cb616a5266')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36591a76aa1041e6b0fd9272e40957c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snapshot_download(repo_id='vinthony/SadTalker-V002rc', local_dir='./checkpoints', local_dir_use_symlinks=True)\n",
    "\n",
    "sad_talker = SadTalker(lazy_load=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:24:57.852240207Z",
     "start_time": "2024-01-26T07:24:56.876414734Z"
    }
   },
   "id": "6ca050e680068727",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['a',\n 'b',\n 'c',\n 'd',\n 'e',\n 'f',\n 'g',\n 'h',\n 'i',\n 'j',\n 'k',\n 'l',\n 'm',\n 'n',\n 'o',\n 'p',\n 'q',\n 'r',\n 's',\n 't',\n 'u',\n 'v',\n 'w',\n 'x',\n 'y',\n 'z',\n 'ba',\n 'bi',\n 'bu',\n 'be',\n 'bo',\n 'ca',\n 'ci',\n 'cu',\n 'ce',\n 'co',\n 'da',\n 'di',\n 'du',\n 'de',\n 'do',\n 'fa',\n 'fi',\n 'fu',\n 'fe',\n 'fo',\n 'ga',\n 'gi',\n 'gu',\n 'ge',\n 'go',\n 'ha',\n 'hi',\n 'hu',\n 'he',\n 'ho',\n 'ja',\n 'ji',\n 'ju',\n 'je',\n 'jo',\n 'ka',\n 'ki',\n 'ku',\n 'ke',\n 'ko',\n 'la',\n 'li',\n 'lu',\n 'le',\n 'lo',\n 'ma',\n 'mi',\n 'mu',\n 'me',\n 'mo',\n 'na',\n 'ni',\n 'nu',\n 'ne',\n 'no',\n 'pa',\n 'pi',\n 'pu',\n 'pe',\n 'po',\n 'qa',\n 'qi',\n 'qu',\n 'qe',\n 'qo',\n 'ra',\n 'ri',\n 'ru',\n 're',\n 'ro',\n 'sa',\n 'si',\n 'su',\n 'se',\n 'so',\n 'ta',\n 'ti',\n 'tu',\n 'te',\n 'to',\n 'va',\n 'vi',\n 'vu',\n 've',\n 'vo',\n 'wa',\n 'wi',\n 'wu',\n 'we',\n 'wo',\n 'xa',\n 'xi',\n 'xu',\n 'xe',\n 'xo',\n 'ya',\n 'yi',\n 'yu',\n 'ye',\n 'yo',\n 'za',\n 'zi',\n 'zu',\n 'ze',\n 'zo']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kosakata = open(\"kosakata.txt\", \"r\").read().split(\"\\n\")\n",
    "kosakata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:24:57.856861113Z",
     "start_time": "2024-01-26T07:24:57.854446073Z"
    }
   },
   "id": "4bd25d5062deb776",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:29<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(kosakata):\n",
    "    filename = f\"audios/{word}.wav\"\n",
    "    \n",
    "    audio = generate(\n",
    "            text=\"<break time='1s' />\" + word + \"<break time='1s' />\",\n",
    "            model=\"eleven_multilingual_v2\"\n",
    "        )\n",
    "\n",
    "    save(\n",
    "        audio=audio,\n",
    "        filename=filename\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T08:08:08.381414412Z",
     "start_time": "2024-01-26T08:07:39.329333989Z"
    }
   },
   "id": "1c1e776cbc9509d9",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "failed_kosakata = []\n",
    "failed_audio = []\n",
    "\n",
    "for audio in glob(\"audios/*\"):\n",
    "    filename = audio.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    try:\n",
    "        result = sad_talker.test(\n",
    "            source_image=\"images/woman.png\",\n",
    "            driven_audio=audio,\n",
    "            preprocess='crop',\n",
    "            still_mode=True, \n",
    "            use_enhancer=True, \n",
    "            batch_size=1, \n",
    "            size=256,\n",
    "            pose_style=0,\n",
    "            facerender='facevid2vid',\n",
    "            exp_scale=1.0,\n",
    "            use_ref_video=False,\n",
    "            ref_video=None,\n",
    "            ref_info=None,\n",
    "            use_idle_mode=False,\n",
    "            length_of_audio=0, \n",
    "            use_blink=True,\n",
    "            result_dir='./results/'\n",
    "        )\n",
    "    \n",
    "        copy(result, f\"videos/{filename}.mp4\")\n",
    "    except:\n",
    "        failed_kosakata.append(filename)\n",
    "        failed_audio.append(audio)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b28e7002334525a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "failed_video = []\n",
    "\n",
    "for video in glob(\"videos/*\"):\n",
    "    try:\n",
    "        filename = video.split(\"/\")[-1].split(\".\")[0]\n",
    "        \n",
    "        videoClip = VideoFileClip(video)\n",
    "        videoClip.write_gif(f\"gifs/{filename}.gif\")\n",
    "    except:\n",
    "        failed_video.append(video)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2a0be63599d75dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:03<00:00, 28.71it/s]\n"
     ]
    }
   ],
   "source": [
    "size = (512, 512)\n",
    "\n",
    "for gif in tqdm(glob(\"gifs/*\")):\n",
    "    filename = gif.split(\"/\")[-1].split(\".\")[0]\n",
    "    folder_path = f\"sheets/512/{filename}\"\n",
    "    \n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    im = Image.open(gif)\n",
    "\n",
    "    for frame in range(0, im.n_frames):\n",
    "        im.seek(frame)\n",
    "\n",
    "        extracted_frame = im.resize(size)\n",
    "        # extracted_frame = remove(extracted_frame)\n",
    "\n",
    "        extracted_frame.convert('RGB').save(f\"{folder_path}/{filename}_{frame}.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T07:43:42.056667938Z",
     "start_time": "2024-01-26T07:43:38.198747501Z"
    }
   },
   "id": "15c7972fd63f96c5",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fail Safe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a842d1560a6393"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(failed_kosakata_again):\n",
    "    filename = f\"audios/{word}.wav\"\n",
    "    \n",
    "    audio = generate(\n",
    "            text=\"<break time='1s' />\" + word + \"<break time='1s' />\",\n",
    "            model=\"eleven_multilingual_v2\"\n",
    "        )\n",
    "\n",
    "    save(\n",
    "        audio=audio,\n",
    "        filename=filename\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T08:33:36.279486916Z",
     "start_time": "2024-01-26T08:33:30.789578844Z"
    }
   },
   "id": "d2491f8c65ea991d",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using safetensor as default\n",
      "{'checkpoint': 'checkpoints/SadTalker_V0.0.2_256.safetensors', 'dir_of_BFM_fitting': 'src/config', 'audio2pose_yaml_path': 'src/config/auido2pose.yaml', 'audio2exp_yaml_path': 'src/config/auido2exp.yaml', 'pirender_yaml_path': 'src/config/facerender_pirender.yaml', 'pirender_checkpoint': 'checkpoints/epoch_00190_iteration_000400000_checkpoint.pt', 'use_safetensor': True, 'mappingnet_checkpoint': 'checkpoints/mapping_00229-model.pth.tar', 'facerender_yaml': 'src/config/facerender.yaml'}\n",
      "images/woman.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "landmark Det:: 100%|██████████| 1/1 [00:00<00:00, 40.49it/s]\n",
      "3DMM Extraction In Video:: 100%|██████████| 1/1 [00:00<00:00, 169.12it/s]\n",
      "mel:: 100%|██████████| 20/20 [00:00<00:00, 89910.05it/s]\n",
      "audio2exp:: 100%|██████████| 2/2 [00:00<00:00, 890.60it/s]\n",
      "Face Renderer:: 100%|██████████| 20/20 [00:03<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated video is named ./results/efb1321d-bd82-407c-8fe6-7d9d481895fe/woman##mi.mp4\n",
      "face enhancer....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Face Enhancer:: 100%|██████████| 20/20 [00:03<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated video is named ./results/efb1321d-bd82-407c-8fe6-7d9d481895fe/woman##mi_enhanced.mp4\n",
      "The generated video is named woman##mi in ./results/efb1321d-bd82-407c-8fe6-7d9d481895fe\n",
      "using safetensor as default\n",
      "{'checkpoint': 'checkpoints/SadTalker_V0.0.2_256.safetensors', 'dir_of_BFM_fitting': 'src/config', 'audio2pose_yaml_path': 'src/config/auido2pose.yaml', 'audio2exp_yaml_path': 'src/config/auido2exp.yaml', 'pirender_yaml_path': 'src/config/facerender_pirender.yaml', 'pirender_checkpoint': 'checkpoints/epoch_00190_iteration_000400000_checkpoint.pt', 'use_safetensor': True, 'mappingnet_checkpoint': 'checkpoints/mapping_00229-model.pth.tar', 'facerender_yaml': 'src/config/facerender.yaml'}\n",
      "images/woman.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "landmark Det:: 100%|██████████| 1/1 [00:00<00:00, 39.90it/s]\n",
      "3DMM Extraction In Video:: 100%|██████████| 1/1 [00:00<00:00, 156.64it/s]\n",
      "mel:: 100%|██████████| 22/22 [00:00<00:00, 91815.61it/s]\n",
      "audio2exp:: 100%|██████████| 3/3 [00:00<00:00, 998.09it/s]\n",
      "Face Renderer:: 100%|██████████| 22/22 [00:03<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated video is named ./results/1f304b44-6ccc-4fa0-aeb3-93534c59c0a6/woman##na.mp4\n",
      "face enhancer....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Face Enhancer:: 100%|██████████| 22/22 [00:04<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated video is named ./results/1f304b44-6ccc-4fa0-aeb3-93534c59c0a6/woman##na_enhanced.mp4\n",
      "The generated video is named woman##na in ./results/1f304b44-6ccc-4fa0-aeb3-93534c59c0a6\n",
      "using safetensor as default\n",
      "{'checkpoint': 'checkpoints/SadTalker_V0.0.2_256.safetensors', 'dir_of_BFM_fitting': 'src/config', 'audio2pose_yaml_path': 'src/config/auido2pose.yaml', 'audio2exp_yaml_path': 'src/config/auido2exp.yaml', 'pirender_yaml_path': 'src/config/facerender_pirender.yaml', 'pirender_checkpoint': 'checkpoints/epoch_00190_iteration_000400000_checkpoint.pt', 'use_safetensor': True, 'mappingnet_checkpoint': 'checkpoints/mapping_00229-model.pth.tar', 'facerender_yaml': 'src/config/facerender.yaml'}\n",
      "images/woman.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "landmark Det:: 100%|██████████| 1/1 [00:00<00:00, 26.99it/s]\n",
      "3DMM Extraction In Video:: 100%|██████████| 1/1 [00:00<00:00, 162.05it/s]\n",
      "mel:: 100%|██████████| 20/20 [00:00<00:00, 58867.42it/s]\n",
      "audio2exp:: 100%|██████████| 2/2 [00:00<00:00, 889.09it/s]\n",
      "Face Renderer:: 100%|██████████| 20/20 [00:03<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated video is named ./results/7b53a836-02a0-4c13-b868-4b43a523fb90/woman##ya.mp4\n",
      "face enhancer....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Face Enhancer:: 100%|██████████| 20/20 [00:04<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated video is named ./results/7b53a836-02a0-4c13-b868-4b43a523fb90/woman##ya_enhanced.mp4\n",
      "The generated video is named woman##ya in ./results/7b53a836-02a0-4c13-b868-4b43a523fb90\n",
      "using safetensor as default\n",
      "{'checkpoint': 'checkpoints/SadTalker_V0.0.2_256.safetensors', 'dir_of_BFM_fitting': 'src/config', 'audio2pose_yaml_path': 'src/config/auido2pose.yaml', 'audio2exp_yaml_path': 'src/config/auido2exp.yaml', 'pirender_yaml_path': 'src/config/facerender_pirender.yaml', 'pirender_checkpoint': 'checkpoints/epoch_00190_iteration_000400000_checkpoint.pt', 'use_safetensor': True, 'mappingnet_checkpoint': 'checkpoints/mapping_00229-model.pth.tar', 'facerender_yaml': 'src/config/facerender.yaml'}\n",
      "images/woman.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "landmark Det:: 100%|██████████| 1/1 [00:00<00:00, 26.19it/s]\n",
      "3DMM Extraction In Video:: 100%|██████████| 1/1 [00:00<00:00, 158.43it/s]\n",
      "mel:: 100%|██████████| 21/21 [00:00<00:00, 77263.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# failed_kosakata_again = []\n",
    "# failed_audio_again = []\n",
    "# \n",
    "# succeed_audio = []\n",
    "\n",
    "for audio in failed_audio_again:\n",
    "    filename = audio.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    try:\n",
    "        result = sad_talker.test(\n",
    "                source_image=\"images/woman.png\",\n",
    "                driven_audio=audio,\n",
    "                preprocess='crop',\n",
    "                still_mode=True, \n",
    "                use_enhancer=True, \n",
    "                batch_size=1, \n",
    "                size=256,\n",
    "                pose_style=0,\n",
    "                facerender='facevid2vid',\n",
    "                exp_scale=1.0,\n",
    "                use_ref_video=False,\n",
    "                ref_video=None,\n",
    "                ref_info=None,\n",
    "                use_idle_mode=False,\n",
    "                length_of_audio=0, \n",
    "                use_blink=True,\n",
    "                result_dir='./results/'\n",
    "            )\n",
    "    \n",
    "        copy(result, f\"videos/{filename}.mp4\")\n",
    "        \n",
    "        succeed_audio.append(f\"videos/{filename}.mp4\")\n",
    "    except:\n",
    "        # failed_kosakata_again.append(filename)\n",
    "        # failed_audio_again.append(audio)\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T08:34:10.105240084Z",
     "start_time": "2024-01-26T08:33:37.110538221Z"
    }
   },
   "id": "9a66b41ee2f30b21",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "succeed_video = []\n",
    "\n",
    "for video in tqdm(succeed_audio):\n",
    "    try:\n",
    "        filename = video.split(\"/\")[-1].split(\".\")[0]\n",
    "        \n",
    "        videoClip = VideoFileClip(video)\n",
    "        videoClip.write_gif(f\"gifs/{filename}.gif\")\n",
    "        \n",
    "        succeed_video.append(f\"gifs/{filename}.gif\")\n",
    "    except:\n",
    "        failed_video.append(video)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffa97ab5de11301d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 27.82it/s]\n"
     ]
    }
   ],
   "source": [
    "size = (512, 512)\n",
    "\n",
    "for gif in tqdm(succeed_video):\n",
    "    filename = gif.split(\"/\")[-1].split(\".\")[0]\n",
    "    folder_path = f\"sheets/512/{filename}\"\n",
    "    \n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    im = Image.open(gif)\n",
    "\n",
    "    for frame in range(0, im.n_frames):\n",
    "        im.seek(frame)\n",
    "\n",
    "        extracted_frame = im.resize(size)\n",
    "        # extracted_frame = remove(extracted_frame)\n",
    "\n",
    "        extracted_frame.convert('RGB').save(f\"{folder_path}/{filename}_{frame}.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T08:57:27.336659629Z",
     "start_time": "2024-01-26T08:57:26.502091403Z"
    }
   },
   "id": "4b3f7fa600f6c765",
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
